{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a4f1696c-33ad-4b0d-a231-14796870ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./GoogleClient.ipynb\n",
    "%run ./Utils.ipynb\n",
    "import panoramix\n",
    "from panoramix.decompiler import decompile_bytecode\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "import multiprocessing \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6a865-0761-4a70-b399-6688dcf48a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BytecodeDecompiler:\n",
    "    def __init__(self, google_client, init = False, decompiler_output=Utils.DECOMPILER_OUTPUT_DIR):\n",
    "        \"\"\"\n",
    "        Initialize the BytecodeDecompiler with a GoogleClient and decompiler output directory.\n",
    "\n",
    "        Args:\n",
    "            google_client (GoogleClient): An instance of GoogleClient.\n",
    "            decompiler_output (str): The directory where decompiled bytecodes will be stored.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If google_client is not an instance of GoogleClient.\n",
    "            ValueError: If decompiler_output is not a valid directory path.\n",
    "        \"\"\"\n",
    "        if not isinstance(google_client, GoogleClient):\n",
    "            raise TypeError(\"google_client must be an instance of GoogleClient object!\")\n",
    "        self.google_client = google_client\n",
    "\n",
    "        if not isinstance(decompiler_output, str) or not decompiler_output:\n",
    "            raise ValueError(\"decompiler_output must be a non-empty string representing a directory path.\")\n",
    "        \n",
    "        # Ensure the decompiler_output is an absolute path\n",
    "        self.decompiler_output = os.path.abspath(decompiler_output)\n",
    "        self.df_all_contracts_bytecodes = \"df-all-contracts-bytecodes\"\n",
    "        self.df_all_contracts_asof = \"df-all-contracts-asof\"\n",
    "        self.df_all_distinct_bytecodes_hashes = \"df-all-distinct-bytecodes-hashes\"\n",
    "        self.df_all_contracts_bytecodes_hashes = \"df-all-contracts-bytecode-hashes\"\n",
    "\n",
    "        if init:\n",
    "            self.initialize()\n",
    "            \n",
    "        Utils.create_directory(self.decompiler_output)\n",
    "        \n",
    "        self.decomiled_bytecodes = self.load_decompiled_bytecodes()\n",
    "        \n",
    "        db_path = os.path.join(Utils.DATA_DIR, \"bytecodes_cache.db\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        contracts_hashes_csv_dir = os.path.join(self.google_client.storage_bucket_decompresssed_path, self.df_all_contracts_bytecodes_hashes)\n",
    "        self.contracts_bytecodes_hash = SQLiteProxyDict(\n",
    "            db_path=db_path,\n",
    "            table_name=\"contracts_bytecode_hashes\", # Table name in SQLite\n",
    "            key_column=\"from_address\",\n",
    "            value_column=\"bytecode_hash\",\n",
    "            csv_path=contracts_hashes_csv_dir, # Directory path containing CSV files\n",
    "            force_reload=init,\n",
    "        )\n",
    "\n",
    "        # Path to the directory containing CSVs for distinct_bytecodes_hash\n",
    "        distinct_hashes_csv_dir = os.path.join(self.google_client.storage_bucket_decompresssed_path, self.df_all_distinct_bytecodes_hashes)\n",
    "        self.distinct_bytecodes_hash  = SQLiteProxyDict(\n",
    "            db_path=db_path,\n",
    "            table_name=\"distinct_bytecodes_hashes\", # Table name in SQLite\n",
    "            key_column=\"bytecode_hash\",\n",
    "            value_column=\"bytecode\",\n",
    "            csv_path=distinct_hashes_csv_dir, # Directory path containing CSV files\n",
    "            force_reload=init,\n",
    "        )\n",
    "        \n",
    "        #self.contracts_bytecodes_hash = Utils.convert_to_dict(Utils.multicore_read_csv(os.path.join(self.google_client.storage_bucket_decompresssed_path, self.df_all_contracts_bytecodes_hashes)), \"from_address\", \"bytecode_hash\")\n",
    "        #self.distinct_bytecodes_hash  = Utils.convert_to_dict(Utils.multicore_read_csv(os.path.join(self.google_client.storage_bucket_decompresssed_path, self.df_all_distinct_bytecodes_hashes)), \"bytecode_hash\", \"bytecode\")\n",
    "        self.total_decompilation_time = 0\n",
    "        \n",
    "    def initialize(self):\n",
    "        # create a dataset if not exist\n",
    "        self.google_client.create_dataset(override=False)\n",
    "        # retrive all contracts bytecodes and hash their bytecodes\n",
    "        self.google_client.hash_contracts_bytecodes(self.df_all_contracts_bytecodes, keep = 'latest', override=True)\n",
    "        # collect all contracts deployed\n",
    "        self.google_client.collect_contract_addresses_as_of(self.df_all_contracts_asof, \"2040-01-01\", override=True)\n",
    "        # collect and download the distinct set of bytecode along with their hashes\n",
    "        self.google_client.download_distinct_bytecode_hashes(self.df_all_contracts_bytecodes, self.df_all_contracts_asof, self.df_all_distinct_bytecodes_hashes, override = True)\n",
    "        # collect all contracts bytecodes hash\n",
    "        self.google_client.download_contracts_bytecode_hashes(self.df_all_contracts_bytecodes, self.df_all_contracts_asof, self.df_all_contracts_bytecodes_hashes, override = True)\n",
    "\n",
    "    def load_decompiled_bytecodes(self):\n",
    "        \"\"\"\n",
    "        This function reads all the files in a decompiled-bytecodes directory and returns a dictionary\n",
    "        with the filenames as keys and their absolute paths as values.\n",
    "    \n",
    "        Returns:\n",
    "        dict: A dictionary with filenames as keys and their absolute paths as values.\n",
    "        \"\"\"\n",
    "        files_dict = {}\n",
    "    \n",
    "        try:\n",
    "            # Iterate over all the entries in the directory\n",
    "            for entry in os.listdir(self.decompiler_output):\n",
    "                # Construct the full path\n",
    "                full_path = os.path.join(self.decompiler_output, entry)\n",
    "                # Get the absolute path\n",
    "                absolute_path = os.path.abspath(full_path)\n",
    "                # Check if it's a file\n",
    "                if os.path.isfile(absolute_path):\n",
    "                    # Add to the dictionary\n",
    "                    files_dict[entry.split('.')[0]] = absolute_path\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading the directory: {e}\")\n",
    "    \n",
    "        return files_dict\n",
    "    \n",
    "    def reload_decompiled_bytecodes(self):\n",
    "        self.decomiled_bytecodes = self.load_decompiled_bytecodes()\n",
    "    \n",
    "    def run_panoramix(self, contract_bytecode, timeout):\n",
    "        def target():\n",
    "            global decompiled_bytecode\n",
    "            # Replace 'self.distinct_bytecodes_hash[self.contracts_bytecodes_hash[address]]' with the actual bytecode or logic to obtain it.\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    ['panoramix', contract_bytecode],\n",
    "                    capture_output=True,\n",
    "                    text=True\n",
    "                )\n",
    "                decompiled_bytecode = result.stdout\n",
    "            except Exception as e:\n",
    "                decompiled_bytecode = None\n",
    "                print(f\"Error: {e}\")\n",
    "    \n",
    "        thread = threading.Thread(target=target)\n",
    "        thread.start()\n",
    "        thread.join(timeout=timeout)  # maximum 300 seconds in single core processing mode.\n",
    "    \n",
    "        if thread.is_alive() or decompiled_bytecode is None:\n",
    "            return False # either timeout or exception\n",
    "        else:\n",
    "            return decompiled_bytecode\n",
    "        \n",
    "    def decompile_contract(self, address, timeout=900):\n",
    "        if address in self.contracts_bytecodes_hash:\n",
    "            if str(self.contracts_bytecodes_hash[address]) in self.decomiled_bytecodes: \n",
    "                return self.decomiled_bytecodes[str(self.contracts_bytecodes_hash[address])]\n",
    "            else:\n",
    "                if self.contracts_bytecodes_hash[address] in self.distinct_bytecodes_hash:\n",
    "                    start_time = time.time()  # Start the timer\n",
    "                    decompiled_bytecode = self.run_panoramix(self.distinct_bytecodes_hash[self.contracts_bytecodes_hash[address]], timeout)\n",
    "                    end_time = time.time()  # End the timer\n",
    "                    self.total_decompilation_time += (end_time - start_time)\n",
    "                    if decompiled_bytecode:\n",
    "                        bytecode_path = os.path.join(self.decompiler_output, \"{}.txt\".format(self.contracts_bytecodes_hash[address]))\n",
    "                        with open (bytecode_path, 'w') as writer:\n",
    "                            writer.write(Utils.escape_ansi(decompiled_bytecode))\n",
    "                        # update the list of decompiled bytecodes\n",
    "                        self.decomiled_bytecodes[str(self.contracts_bytecodes_hash[address])] = bytecode_path\n",
    "                        return bytecode_path\n",
    "                    else:\n",
    "                        return 'Failure: Decompiler error'\n",
    "                else:\n",
    "                    # Raise error that contract's bytecode hash not found in distinct_bytecodes_hash.\n",
    "                    raise KeyError(\"Contract's bytecode hash not found in distinct_bytecodes_hash. Update to the latest snapshot of Ethereum by calling the initialize function.\")\n",
    "        else:\n",
    "            # Raise error that contract address not found in contracts_bytecodes_hash.\n",
    "            raise KeyError(\"Contract address not found in contracts_bytecodes_hash. Update to the latest snapshot of Ethereum by calling the initialize function.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "200e0a38-b906-4de1-bbff-fb21d9fd23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_panoramix(contract_bytecode, timeout = Utils.DECOMPILER_TIMEOUT):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['panoramix', contract_bytecode],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=timeout  # Set the timeout to 2 minutes (120 seconds)\n",
    "        )\n",
    "        return result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Timeout: Decompilation\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def decompile_contract(args):\n",
    "    bytecode_hash, bytecode, decompiler_output, timeout = args\n",
    "    \n",
    "    decompiled_bytecode = run_panoramix(bytecode, timeout)\n",
    "    if decompiled_bytecode:\n",
    "        bytecode_path = os.path.join(decompiler_output, \"{}.txt\".format(bytecode_hash))\n",
    "        with open(bytecode_path, 'w') as writer:\n",
    "            writer.write(Utils.escape_ansi(decompiled_bytecode))\n",
    "\n",
    "def load_decompiled_bytecodes(decompiler_output):\n",
    "    \"\"\"\n",
    "    This function reads all the files in a decompiled-bytecodes directory and returns a dictionary\n",
    "    with the filenames as keys and their absolute paths as values.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with filenames as keys and their absolute paths as values.\n",
    "    \"\"\"\n",
    "    files_dict = {}\n",
    "\n",
    "    try:\n",
    "        # Iterate over all the entries in the directory\n",
    "        for entry in os.listdir(decompiler_output):\n",
    "            # Construct the full path\n",
    "            full_path = os.path.join(decompiler_output, entry)\n",
    "            # Get the absolute path\n",
    "            absolute_path = os.path.abspath(full_path)\n",
    "            # Check if it's a file\n",
    "            if os.path.isfile(absolute_path):\n",
    "                # Add to the dictionary\n",
    "                files_dict[entry.split('.')[0]] = absolute_path\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the directory: {e}\")\n",
    "\n",
    "    return files_dict\n",
    "        \n",
    "def decompile_contracts_in_parallel(addresses, contracts_bytecodes_hash, distinct_bytecodes_hash, decompiler_output, timeout = Utils.DECOMPILER_TIMEOUT):\n",
    "    all_decompiled_files = load_decompiled_bytecodes(decompiler_output)\n",
    "    _input = dict()\n",
    "    for address in addresses:\n",
    "        if str(contracts_bytecodes_hash[address]) not in all_decompiled_files:\n",
    "            try:\n",
    "                _input[contracts_bytecodes_hash[address]] = distinct_bytecodes_hash[contracts_bytecodes_hash[address]]\n",
    "            except:\n",
    "                print(\"contracts bytecode {} not found\".format(address))\n",
    "    args = []\n",
    "    for _hash in _input.keys():\n",
    "        args.append((_hash, _input[_hash], decompiler_output, timeout))\n",
    "\n",
    "\n",
    "    if len(args) == 0:\n",
    "        return 0\n",
    "    \n",
    "    start_time = time.time()  # Start the timer\n",
    "    print('number of decompilation jobs after excluding duplicates:', len(args))\n",
    "    with multiprocessing.Pool(processes=Utils.CORE_COUNT) as pool:\n",
    "        pool.map(decompile_contract, args)\n",
    "\n",
    "    end_time = time.time()  # End the timer\n",
    "    return end_time - start_time  # Calculate the difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
