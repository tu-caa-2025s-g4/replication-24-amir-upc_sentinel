{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b504c4-1bec-4402-aae9-0aad013cbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import glob\n",
    "import re\n",
    "import multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79eb586a-b38c-4eaa-8ca1-0e877ac84ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils: \n",
    "\n",
    "    DATA_DIR = os.path.abspath(\"../storage/\")\n",
    "    DECOMPILER_OUTPUT_DIR = os.path.join(DATA_DIR, 'decompiled-bytecodes')\n",
    "    DECOMPILER_TIMEOUT = 3600\n",
    "    STUDY_START_DATE = \"2015-01-01\"\n",
    "    STUDY_END_DATE = \"2022-09-01\"\n",
    "    \n",
    "    BQ_KEY_PATH = 'lateral-command-433401-d4-89aa899f9420.json'\n",
    "    BQ_PROJECT_ID = '-'.join(BQ_KEY_PATH.split(\"-\")[:len(BQ_KEY_PATH.split(\"-\")) -1])\n",
    "    BQ_STORAGE_PROXY_DETECTOR = 'storage_dynamic_proxy_detector'\n",
    "    BQ_STORAGE_BYTECODES = 'storage_bytecodes'    \n",
    "    CORE_COUNT = int(multiprocessing.cpu_count() * 0.75) # 80 * .75 = 60\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_directory(directory_path, override= False):\n",
    "        \"\"\"\n",
    "        This function checks if the specified directory exists, deletes it along with its contents if overrides set true,\n",
    "        and if director does not exist it creates an empty directory at the same path.\n",
    "    \n",
    "        Parameters:\n",
    "        directory_path (str): The file path to the directory to be checked and recreated.\n",
    "        \"\"\"\n",
    "        # Check if the directory exists\n",
    "        if os.path.exists(directory_path) and override:\n",
    "            # Remove the directory and all its contents\n",
    "            shutil.rmtree(directory_path)\n",
    "            print(f\"Removed existing directory: {directory_path}\")\n",
    "            \n",
    "            # Recreate the directory\n",
    "            os.makedirs(directory_path)\n",
    "            print(f\"Created new directory: {directory_path}\")\n",
    "        \n",
    "        elif not os.path.exists(directory_path):\n",
    "            # create the directory\n",
    "            os.makedirs(directory_path)\n",
    "            print(f\"Created new directory: {directory_path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def multicore_read_csv(target_dir, num_cores=CORE_COUNT):\n",
    "        \"\"\"\n",
    "        Read multiple CSV files from the specified directory using multiple cores.\n",
    "\n",
    "        Args:\n",
    "            target_dir (str): The directory containing the CSV files.\n",
    "            num_cores (int): The number of cores to use for reading the files.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A concatenated DataFrame containing data from all CSV files.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If target_dir is not a directory or num_cores is not a positive integer.\n",
    "            FileNotFoundError: If no CSV files are found in the target directory.\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(target_dir):\n",
    "            raise ValueError(f\"The specified target directory '{target_dir}' is not a valid directory.\")\n",
    "        \n",
    "        if not isinstance(num_cores, int) or num_cores <= 0:\n",
    "            raise ValueError(\"The number of cores must be a positive integer.\")\n",
    "\n",
    "        # Ensure the target directory path ends with a slash\n",
    "        if not target_dir.endswith('/'):\n",
    "            target_dir += '/'\n",
    "        \n",
    "        batches_path = [batch for batch in glob.glob(target_dir + \"*.csv\")]\n",
    "\n",
    "        if len(batches_path) == 0:\n",
    "            raise FileNotFoundError(f\"No CSV files found in the target directory '{target_dir}'.\")\n",
    "\n",
    "        print('Reading {} CSV files from {} directory ...'.format(len(batches_path), target_dir))\n",
    "        \n",
    "        with Pool(num_cores) as p:\n",
    "            df = pd.concat(p.map(pd.read_csv, batches_path), ignore_index=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_dict(dataframe, col1_key, col2_value):\n",
    "        \"\"\"\n",
    "        Convert two columns of a DataFrame into a dictionary with keys from col1_key and values from col2_value.\n",
    "    \n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): The DataFrame containing the data.\n",
    "            col1_key (str): The column name to use as keys in the dictionary.\n",
    "            col2_value (str): The column name to use as values in the dictionary.\n",
    "    \n",
    "        Returns:\n",
    "            dict: A dictionary with keys from col1_key and values from col2_value.\n",
    "    \n",
    "        Raises:\n",
    "            TypeError: If the input dataframe is not a pandas DataFrame.\n",
    "            ValueError: If col1_key or col2_value are not columns in the DataFrame.\n",
    "        \"\"\"\n",
    "        if not isinstance(dataframe, pd.DataFrame):\n",
    "            raise TypeError(\"The input dataframe must be a pandas DataFrame.\")\n",
    "        \n",
    "        if col1_key not in dataframe.columns:\n",
    "            raise ValueError(f\"Column '{col1_key}' is not in the DataFrame.\")\n",
    "        \n",
    "        if col2_value not in dataframe.columns:\n",
    "            raise ValueError(f\"Column '{col2_value}' is not in the DataFrame.\")\n",
    "    \n",
    "        return dict(zip(dataframe[col1_key], dataframe[col2_value]))\n",
    "\n",
    "    @staticmethod\n",
    "    def escape_ansi(line):\n",
    "        ansi_escape =re.compile(r'(\\x9B|\\x1B\\[)[0-?]*[ -\\/]*[@-~]')\n",
    "        return ansi_escape.sub('', line)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
